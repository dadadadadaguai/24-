D:\deeplearning\Anaconda\python.exe D:\developproject\PycharmProjects\ModelingProject\problem1.py
2024-09-23 23:01:02,545 - INFO - 开始执行
(12399, 13)
0.9934742088627141
           0         1         2         3         4         5         6
0   0.972780  2.289039 -0.066369  0.803628  0.090830  0.083222 -0.007740
1  -1.364516  2.143136 -0.069396  0.391968 -0.028937  0.420289  0.081971
2  -0.154888  1.619562 -0.048032  0.198370  0.416427  0.269989 -0.125608
3  -1.641739  1.032703 -0.038556 -0.375686  0.612422  0.457394 -0.148896
4   0.219483  2.107140 -0.066150  0.687252 -0.222964  0.165331 -0.241607
..       ...       ...       ...       ...       ...       ...       ...
75 -2.152523 -1.785093  0.051402 -0.235779 -0.289469 -0.550137 -0.093141
76 -2.262121 -1.458266  0.050231 -0.129860 -0.101354 -0.555857  0.269755
77 -1.075722 -2.612166  0.081887 -0.198280 -0.313015 -0.283622 -0.646758
78 -2.008250 -1.784245  0.053745 -0.316475  0.247079 -0.463517  0.264234
79 -2.271115 -1.643857  0.052060 -0.304761  0.200802 -0.534094  0.333499

[80 rows x 7 columns]
逻辑回归模型在交叉验证中的均方误差：-1.0
逻辑回归模型在训练集上的预测结果：
逻辑回归模型评价结果：
ACC 1.0
REC 1.0
F-score 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00      1212
           2       1.00      1.00      1.00      1458
           3       1.00      1.00      1.00      1050

    accuracy                           1.00      3720
   macro avg       1.00      1.00      1.00      3720
weighted avg       1.00      1.00      1.00      3720

决策树模型在交叉验证中的均方误差：-0.9944695812693395
决策树模型在训练集上的预测结果：
决策树模型评价结果：
ACC 0.9959677419354839
REC 0.9959677419354839
F-score 0.9959677419354839
              precision    recall  f1-score   support

           1       1.00      1.00      1.00      1212
           2       1.00      1.00      1.00      1458
           3       0.99      0.99      0.99      1050

    accuracy                           1.00      3720
   macro avg       1.00      1.00      1.00      3720
weighted avg       1.00      1.00      1.00      3720

随机森林模型在交叉验证中的均方误差：-0.9746513233907489
随机森林模型在训练集上的预测结果：
随机森林模型评价结果：
ACC 0.9723118279569892
REC 0.9723118279569892
F-score 0.9723118279569892
              precision    recall  f1-score   support

           1       0.99      0.98      0.98      1212
           2       0.97      0.99      0.98      1458
           3       0.96      0.94      0.95      1050

    accuracy                           0.97      3720
   macro avg       0.97      0.97      0.97      3720
weighted avg       0.97      0.97      0.97      3720

D:\deeplearning\Anaconda\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
D:\deeplearning\Anaconda\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
D:\deeplearning\Anaconda\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
D:\deeplearning\Anaconda\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
D:\deeplearning\Anaconda\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
D:\deeplearning\Anaconda\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
AdaBoost模型在交叉验证中的均方误差：-0.8468731988472623
AdaBoost模型在训练集上的预测结果：
AdaBoost模型评价结果：
ACC 0.9134408602150538
REC 0.9134408602150538
F-score 0.9134408602150538
              precision    recall  f1-score   support

           1       1.00      0.96      0.98      1212
           2       1.00      0.81      0.90      1458
           3       0.77      1.00      0.87      1050

    accuracy                           0.91      3720
   macro avg       0.92      0.92      0.91      3720
weighted avg       0.93      0.91      0.92      3720

GBDT模型在交叉验证中的均方误差：-0.9982717565970333
GBDT模型在训练集上的预测结果：
GBDT模型评价结果：
ACC 0.9991935483870967
REC 0.9991935483870967
F-score 0.9991935483870967
              precision    recall  f1-score   support

           1       1.00      1.00      1.00      1212
           2       1.00      1.00      1.00      1458
           3       1.00      1.00      1.00      1050

    accuracy                           1.00      3720
   macro avg       1.00      1.00      1.00      3720
weighted avg       1.00      1.00      1.00      3720

(80, 7)
这个模型:逻辑回归的预测结果为[2 2 2 2 2 3 3 3 3 3 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 3 3 3 3 3 2 2
 2 2 2 3 2 3 3 3 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2
 2 1 1 1 1 1]
(80, 7)
这个模型:决策树的预测结果为[2 2 2 2 2 3 3 3 3 3 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 3 3 3 3 3 2 2
 2 2 2 3 2 3 3 3 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2
 2 1 1 1 1 1]
(80, 7)
这个模型:随机森林的预测结果为[2 2 2 2 2 3 3 3 3 3 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 3 3 3 3 3 2 2
 2 2 2 3 2 3 3 3 1 1 3 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2
 2 1 1 1 1 1]
(80, 7)
这个模型:AdaBoost的预测结果为[3 3 2 3 2 3 3 3 3 3 1 1 1 1 3 2 3 3 2 2 3 2 2 2 2 1 1 1 1 1 3 3 3 3 3 2 2
 2 2 2 3 2 3 3 3 1 1 1 1 1 3 2 2 2 2 2 2 3 2 2 3 3 3 2 3 2 3 3 3 2 2 3 3 2
 2 1 1 1 1 1]
(80, 7)
这个模型:GBDT的预测结果为[2 2 2 2 2 3 3 3 3 3 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 3 3 3 3 3 2 2
 2 2 2 3 2 3 3 3 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2
 2 1 1 1 1 1]
2024-09-23 23:03:29,556 - INFO - 执行结束

进程已结束,退出代码0
